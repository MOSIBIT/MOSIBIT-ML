{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driving-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the much needed stuff for training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "responsible-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>wristX</th>\n",
       "      <th>wristY</th>\n",
       "      <th>thumb_CmcX</th>\n",
       "      <th>thumb_CmcY</th>\n",
       "      <th>thumb_McpX</th>\n",
       "      <th>thumb_McpY</th>\n",
       "      <th>thumb_IpX</th>\n",
       "      <th>thumb_IpY</th>\n",
       "      <th>thumb_TipX</th>\n",
       "      <th>...</th>\n",
       "      <th>ring_TipX</th>\n",
       "      <th>ring_TipY</th>\n",
       "      <th>pinky_McpX</th>\n",
       "      <th>pinky_McpY</th>\n",
       "      <th>pinky_PipX</th>\n",
       "      <th>pinky_PipY</th>\n",
       "      <th>pinky_DipX</th>\n",
       "      <th>pinky_DipY</th>\n",
       "      <th>pinky_TipX</th>\n",
       "      <th>pinky_TipY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>614.663780</td>\n",
       "      <td>905.806620</td>\n",
       "      <td>549.961701</td>\n",
       "      <td>910.559009</td>\n",
       "      <td>484.506458</td>\n",
       "      <td>895.301416</td>\n",
       "      <td>446.415693</td>\n",
       "      <td>872.791400</td>\n",
       "      <td>435.599104</td>\n",
       "      <td>...</td>\n",
       "      <td>597.933635</td>\n",
       "      <td>906.572645</td>\n",
       "      <td>621.966362</td>\n",
       "      <td>825.802557</td>\n",
       "      <td>617.009506</td>\n",
       "      <td>835.676272</td>\n",
       "      <td>628.267184</td>\n",
       "      <td>863.719888</td>\n",
       "      <td>636.857986</td>\n",
       "      <td>880.355752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1586.340550</td>\n",
       "      <td>1973.989626</td>\n",
       "      <td>1321.859984</td>\n",
       "      <td>1894.983892</td>\n",
       "      <td>1098.946306</td>\n",
       "      <td>1643.605182</td>\n",
       "      <td>1026.106686</td>\n",
       "      <td>1423.268890</td>\n",
       "      <td>1142.311011</td>\n",
       "      <td>...</td>\n",
       "      <td>1599.906293</td>\n",
       "      <td>1636.526762</td>\n",
       "      <td>1844.856026</td>\n",
       "      <td>1433.191668</td>\n",
       "      <td>1677.424247</td>\n",
       "      <td>1448.975126</td>\n",
       "      <td>1652.730848</td>\n",
       "      <td>1627.551797</td>\n",
       "      <td>1734.164803</td>\n",
       "      <td>1648.017813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1586.658151</td>\n",
       "      <td>1899.797421</td>\n",
       "      <td>1347.672125</td>\n",
       "      <td>1834.859933</td>\n",
       "      <td>1150.592813</td>\n",
       "      <td>1586.523955</td>\n",
       "      <td>1096.266506</td>\n",
       "      <td>1351.857016</td>\n",
       "      <td>1162.683060</td>\n",
       "      <td>...</td>\n",
       "      <td>1619.031085</td>\n",
       "      <td>1549.667838</td>\n",
       "      <td>1807.934423</td>\n",
       "      <td>1360.078092</td>\n",
       "      <td>1668.181927</td>\n",
       "      <td>1352.136308</td>\n",
       "      <td>1661.550659</td>\n",
       "      <td>1533.032684</td>\n",
       "      <td>1746.261959</td>\n",
       "      <td>1546.756997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1609.015491</td>\n",
       "      <td>1907.042126</td>\n",
       "      <td>1332.827688</td>\n",
       "      <td>1813.612083</td>\n",
       "      <td>1129.451521</td>\n",
       "      <td>1560.214301</td>\n",
       "      <td>1071.799619</td>\n",
       "      <td>1348.270438</td>\n",
       "      <td>1158.308507</td>\n",
       "      <td>...</td>\n",
       "      <td>1592.248868</td>\n",
       "      <td>1547.547122</td>\n",
       "      <td>1834.185079</td>\n",
       "      <td>1350.679505</td>\n",
       "      <td>1657.451330</td>\n",
       "      <td>1350.081768</td>\n",
       "      <td>1638.767816</td>\n",
       "      <td>1529.082674</td>\n",
       "      <td>1727.664467</td>\n",
       "      <td>1547.885221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1650.991414</td>\n",
       "      <td>1806.711465</td>\n",
       "      <td>1384.922959</td>\n",
       "      <td>1740.992451</td>\n",
       "      <td>1179.722488</td>\n",
       "      <td>1506.995106</td>\n",
       "      <td>1119.851872</td>\n",
       "      <td>1279.860915</td>\n",
       "      <td>1177.426620</td>\n",
       "      <td>...</td>\n",
       "      <td>1628.596647</td>\n",
       "      <td>1483.385787</td>\n",
       "      <td>1807.114396</td>\n",
       "      <td>1288.052511</td>\n",
       "      <td>1687.552578</td>\n",
       "      <td>1268.021172</td>\n",
       "      <td>1683.299860</td>\n",
       "      <td>1451.865086</td>\n",
       "      <td>1756.480227</td>\n",
       "      <td>1475.592785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Z</td>\n",
       "      <td>632.342100</td>\n",
       "      <td>1417.761445</td>\n",
       "      <td>511.266172</td>\n",
       "      <td>1452.934027</td>\n",
       "      <td>654.702663</td>\n",
       "      <td>1413.266897</td>\n",
       "      <td>992.956877</td>\n",
       "      <td>1352.535844</td>\n",
       "      <td>1304.301739</td>\n",
       "      <td>...</td>\n",
       "      <td>965.736210</td>\n",
       "      <td>1345.040798</td>\n",
       "      <td>1115.571737</td>\n",
       "      <td>1094.783783</td>\n",
       "      <td>1257.244349</td>\n",
       "      <td>1213.543057</td>\n",
       "      <td>1127.177358</td>\n",
       "      <td>1351.791143</td>\n",
       "      <td>998.408437</td>\n",
       "      <td>1384.162068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Z</td>\n",
       "      <td>707.776546</td>\n",
       "      <td>1417.585611</td>\n",
       "      <td>533.494473</td>\n",
       "      <td>1449.532986</td>\n",
       "      <td>626.750469</td>\n",
       "      <td>1442.848206</td>\n",
       "      <td>935.930610</td>\n",
       "      <td>1423.299432</td>\n",
       "      <td>1238.717318</td>\n",
       "      <td>...</td>\n",
       "      <td>934.907556</td>\n",
       "      <td>1375.932932</td>\n",
       "      <td>1138.646483</td>\n",
       "      <td>1136.404514</td>\n",
       "      <td>1227.160931</td>\n",
       "      <td>1300.656319</td>\n",
       "      <td>1077.356815</td>\n",
       "      <td>1399.181604</td>\n",
       "      <td>964.920759</td>\n",
       "      <td>1406.220436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Z</td>\n",
       "      <td>484.730750</td>\n",
       "      <td>1203.294873</td>\n",
       "      <td>609.190941</td>\n",
       "      <td>1234.577775</td>\n",
       "      <td>845.985651</td>\n",
       "      <td>1188.504934</td>\n",
       "      <td>1064.718962</td>\n",
       "      <td>1230.792642</td>\n",
       "      <td>1245.759130</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.254124</td>\n",
       "      <td>1246.820688</td>\n",
       "      <td>937.975585</td>\n",
       "      <td>1005.628824</td>\n",
       "      <td>1131.682754</td>\n",
       "      <td>1035.978436</td>\n",
       "      <td>1161.693215</td>\n",
       "      <td>1084.606409</td>\n",
       "      <td>1170.148134</td>\n",
       "      <td>1053.281426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Z</td>\n",
       "      <td>445.235610</td>\n",
       "      <td>1298.323512</td>\n",
       "      <td>468.829751</td>\n",
       "      <td>1329.984903</td>\n",
       "      <td>677.648187</td>\n",
       "      <td>1299.878120</td>\n",
       "      <td>947.729409</td>\n",
       "      <td>1341.548443</td>\n",
       "      <td>1169.836998</td>\n",
       "      <td>...</td>\n",
       "      <td>903.057277</td>\n",
       "      <td>1266.618848</td>\n",
       "      <td>957.399011</td>\n",
       "      <td>1050.945640</td>\n",
       "      <td>1096.230984</td>\n",
       "      <td>1104.877949</td>\n",
       "      <td>1034.316659</td>\n",
       "      <td>1175.140142</td>\n",
       "      <td>995.093167</td>\n",
       "      <td>1144.306540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Z</td>\n",
       "      <td>550.345659</td>\n",
       "      <td>1311.316252</td>\n",
       "      <td>553.188920</td>\n",
       "      <td>1309.291124</td>\n",
       "      <td>761.222124</td>\n",
       "      <td>1277.625799</td>\n",
       "      <td>1033.439517</td>\n",
       "      <td>1299.137354</td>\n",
       "      <td>1267.425895</td>\n",
       "      <td>...</td>\n",
       "      <td>960.366845</td>\n",
       "      <td>1254.362702</td>\n",
       "      <td>1017.805338</td>\n",
       "      <td>1062.273979</td>\n",
       "      <td>1146.723390</td>\n",
       "      <td>1102.788806</td>\n",
       "      <td>1068.720341</td>\n",
       "      <td>1209.428310</td>\n",
       "      <td>998.680770</td>\n",
       "      <td>1223.415375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1033 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_type       wristX       wristY   thumb_CmcX   thumb_CmcY  \\\n",
       "0             A   614.663780   905.806620   549.961701   910.559009   \n",
       "1             A  1586.340550  1973.989626  1321.859984  1894.983892   \n",
       "2             A  1586.658151  1899.797421  1347.672125  1834.859933   \n",
       "3             A  1609.015491  1907.042126  1332.827688  1813.612083   \n",
       "4             A  1650.991414  1806.711465  1384.922959  1740.992451   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "1028          Z   632.342100  1417.761445   511.266172  1452.934027   \n",
       "1029          Z   707.776546  1417.585611   533.494473  1449.532986   \n",
       "1030          Z   484.730750  1203.294873   609.190941  1234.577775   \n",
       "1031          Z   445.235610  1298.323512   468.829751  1329.984903   \n",
       "1032          Z   550.345659  1311.316252   553.188920  1309.291124   \n",
       "\n",
       "       thumb_McpX   thumb_McpY    thumb_IpX    thumb_IpY   thumb_TipX  ...  \\\n",
       "0      484.506458   895.301416   446.415693   872.791400   435.599104  ...   \n",
       "1     1098.946306  1643.605182  1026.106686  1423.268890  1142.311011  ...   \n",
       "2     1150.592813  1586.523955  1096.266506  1351.857016  1162.683060  ...   \n",
       "3     1129.451521  1560.214301  1071.799619  1348.270438  1158.308507  ...   \n",
       "4     1179.722488  1506.995106  1119.851872  1279.860915  1177.426620  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1028   654.702663  1413.266897   992.956877  1352.535844  1304.301739  ...   \n",
       "1029   626.750469  1442.848206   935.930610  1423.299432  1238.717318  ...   \n",
       "1030   845.985651  1188.504934  1064.718962  1230.792642  1245.759130  ...   \n",
       "1031   677.648187  1299.878120   947.729409  1341.548443  1169.836998  ...   \n",
       "1032   761.222124  1277.625799  1033.439517  1299.137354  1267.425895  ...   \n",
       "\n",
       "        ring_TipX    ring_TipY   pinky_McpX   pinky_McpY   pinky_PipX  \\\n",
       "0      597.933635   906.572645   621.966362   825.802557   617.009506   \n",
       "1     1599.906293  1636.526762  1844.856026  1433.191668  1677.424247   \n",
       "2     1619.031085  1549.667838  1807.934423  1360.078092  1668.181927   \n",
       "3     1592.248868  1547.547122  1834.185079  1350.679505  1657.451330   \n",
       "4     1628.596647  1483.385787  1807.114396  1288.052511  1687.552578   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1028   965.736210  1345.040798  1115.571737  1094.783783  1257.244349   \n",
       "1029   934.907556  1375.932932  1138.646483  1136.404514  1227.160931   \n",
       "1030  1007.254124  1246.820688   937.975585  1005.628824  1131.682754   \n",
       "1031   903.057277  1266.618848   957.399011  1050.945640  1096.230984   \n",
       "1032   960.366845  1254.362702  1017.805338  1062.273979  1146.723390   \n",
       "\n",
       "       pinky_PipY   pinky_DipX   pinky_DipY   pinky_TipX   pinky_TipY  \n",
       "0      835.676272   628.267184   863.719888   636.857986   880.355752  \n",
       "1     1448.975126  1652.730848  1627.551797  1734.164803  1648.017813  \n",
       "2     1352.136308  1661.550659  1533.032684  1746.261959  1546.756997  \n",
       "3     1350.081768  1638.767816  1529.082674  1727.664467  1547.885221  \n",
       "4     1268.021172  1683.299860  1451.865086  1756.480227  1475.592785  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "1028  1213.543057  1127.177358  1351.791143   998.408437  1384.162068  \n",
       "1029  1300.656319  1077.356815  1399.181604   964.920759  1406.220436  \n",
       "1030  1035.978436  1161.693215  1084.606409  1170.148134  1053.281426  \n",
       "1031  1104.877949  1034.316659  1175.140142   995.093167  1144.306540  \n",
       "1032  1102.788806  1068.720341  1209.428310   998.680770  1223.415375  \n",
       "\n",
       "[1033 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file for Training the model using Pandas\n",
    "df_train = pd.read_csv(\"hands_SIBI_training.csv\", header=0)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>wristX</th>\n",
       "      <th>wristY</th>\n",
       "      <th>thumb_CmcX</th>\n",
       "      <th>thumb_CmcY</th>\n",
       "      <th>thumb_McpX</th>\n",
       "      <th>thumb_McpY</th>\n",
       "      <th>thumb_IpX</th>\n",
       "      <th>thumb_IpY</th>\n",
       "      <th>thumb_TipX</th>\n",
       "      <th>...</th>\n",
       "      <th>ring_TipX</th>\n",
       "      <th>ring_TipY</th>\n",
       "      <th>pinky_McpX</th>\n",
       "      <th>pinky_McpY</th>\n",
       "      <th>pinky_PipX</th>\n",
       "      <th>pinky_PipY</th>\n",
       "      <th>pinky_DipX</th>\n",
       "      <th>pinky_DipY</th>\n",
       "      <th>pinky_TipX</th>\n",
       "      <th>pinky_TipY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1595.475198</td>\n",
       "      <td>1713.882845</td>\n",
       "      <td>1371.011287</td>\n",
       "      <td>1654.651115</td>\n",
       "      <td>1140.459070</td>\n",
       "      <td>1461.532063</td>\n",
       "      <td>1041.989141</td>\n",
       "      <td>1233.009396</td>\n",
       "      <td>1109.759125</td>\n",
       "      <td>...</td>\n",
       "      <td>1564.787345</td>\n",
       "      <td>1370.234713</td>\n",
       "      <td>1741.941414</td>\n",
       "      <td>1206.933278</td>\n",
       "      <td>1664.283545</td>\n",
       "      <td>1119.481146</td>\n",
       "      <td>1645.726819</td>\n",
       "      <td>1310.211016</td>\n",
       "      <td>1689.494687</td>\n",
       "      <td>1349.412327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>719.049096</td>\n",
       "      <td>1577.525616</td>\n",
       "      <td>508.609653</td>\n",
       "      <td>1392.832041</td>\n",
       "      <td>435.399145</td>\n",
       "      <td>1078.577757</td>\n",
       "      <td>453.572810</td>\n",
       "      <td>842.452109</td>\n",
       "      <td>486.912608</td>\n",
       "      <td>...</td>\n",
       "      <td>843.840003</td>\n",
       "      <td>1323.482871</td>\n",
       "      <td>1090.264320</td>\n",
       "      <td>1240.741253</td>\n",
       "      <td>1128.179789</td>\n",
       "      <td>1106.518865</td>\n",
       "      <td>1024.695754</td>\n",
       "      <td>1242.374778</td>\n",
       "      <td>977.687418</td>\n",
       "      <td>1327.082992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>757.780492</td>\n",
       "      <td>1601.105571</td>\n",
       "      <td>552.570701</td>\n",
       "      <td>1429.801345</td>\n",
       "      <td>481.703639</td>\n",
       "      <td>1114.173293</td>\n",
       "      <td>499.344498</td>\n",
       "      <td>878.003299</td>\n",
       "      <td>518.134713</td>\n",
       "      <td>...</td>\n",
       "      <td>877.598047</td>\n",
       "      <td>1347.837567</td>\n",
       "      <td>1113.693476</td>\n",
       "      <td>1258.446693</td>\n",
       "      <td>1158.711910</td>\n",
       "      <td>1131.860495</td>\n",
       "      <td>1060.676217</td>\n",
       "      <td>1270.025492</td>\n",
       "      <td>1010.870814</td>\n",
       "      <td>1352.582455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>615.760669</td>\n",
       "      <td>1031.698437</td>\n",
       "      <td>546.501115</td>\n",
       "      <td>1009.297512</td>\n",
       "      <td>496.653780</td>\n",
       "      <td>939.493802</td>\n",
       "      <td>477.223635</td>\n",
       "      <td>880.857238</td>\n",
       "      <td>457.223967</td>\n",
       "      <td>...</td>\n",
       "      <td>606.932983</td>\n",
       "      <td>927.758379</td>\n",
       "      <td>666.484147</td>\n",
       "      <td>879.113685</td>\n",
       "      <td>633.975327</td>\n",
       "      <td>843.605268</td>\n",
       "      <td>628.140047</td>\n",
       "      <td>895.670514</td>\n",
       "      <td>643.053487</td>\n",
       "      <td>913.554010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>322.910583</td>\n",
       "      <td>3155.554688</td>\n",
       "      <td>387.274112</td>\n",
       "      <td>3209.536560</td>\n",
       "      <td>392.819341</td>\n",
       "      <td>3277.465576</td>\n",
       "      <td>393.364716</td>\n",
       "      <td>3335.383026</td>\n",
       "      <td>401.043561</td>\n",
       "      <td>...</td>\n",
       "      <td>311.369056</td>\n",
       "      <td>3373.221863</td>\n",
       "      <td>272.978125</td>\n",
       "      <td>3264.753571</td>\n",
       "      <td>278.960250</td>\n",
       "      <td>3301.982941</td>\n",
       "      <td>294.675690</td>\n",
       "      <td>3319.776947</td>\n",
       "      <td>307.635242</td>\n",
       "      <td>3325.865021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Z</td>\n",
       "      <td>758.030560</td>\n",
       "      <td>2493.725372</td>\n",
       "      <td>555.423833</td>\n",
       "      <td>2410.149605</td>\n",
       "      <td>554.325989</td>\n",
       "      <td>2121.368992</td>\n",
       "      <td>785.251643</td>\n",
       "      <td>1939.650558</td>\n",
       "      <td>1009.190364</td>\n",
       "      <td>...</td>\n",
       "      <td>836.804911</td>\n",
       "      <td>1998.270870</td>\n",
       "      <td>878.059498</td>\n",
       "      <td>1776.177761</td>\n",
       "      <td>1103.563620</td>\n",
       "      <td>1768.856277</td>\n",
       "      <td>1011.302115</td>\n",
       "      <td>1940.822914</td>\n",
       "      <td>882.944364</td>\n",
       "      <td>1985.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Z</td>\n",
       "      <td>2576.749849</td>\n",
       "      <td>2868.969537</td>\n",
       "      <td>2432.240124</td>\n",
       "      <td>2800.074300</td>\n",
       "      <td>2270.718741</td>\n",
       "      <td>2749.498940</td>\n",
       "      <td>2145.062299</td>\n",
       "      <td>2784.001738</td>\n",
       "      <td>2058.201814</td>\n",
       "      <td>...</td>\n",
       "      <td>2296.587610</td>\n",
       "      <td>2895.431664</td>\n",
       "      <td>2441.918750</td>\n",
       "      <td>2826.890079</td>\n",
       "      <td>2278.390603</td>\n",
       "      <td>2947.817417</td>\n",
       "      <td>2309.023933</td>\n",
       "      <td>2981.885049</td>\n",
       "      <td>2355.511651</td>\n",
       "      <td>2958.717896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Z</td>\n",
       "      <td>1902.547185</td>\n",
       "      <td>2725.740898</td>\n",
       "      <td>1779.595316</td>\n",
       "      <td>2662.946720</td>\n",
       "      <td>1690.045661</td>\n",
       "      <td>2521.979805</td>\n",
       "      <td>1711.686770</td>\n",
       "      <td>2370.669079</td>\n",
       "      <td>1794.469457</td>\n",
       "      <td>...</td>\n",
       "      <td>1875.205433</td>\n",
       "      <td>2507.626522</td>\n",
       "      <td>2008.996679</td>\n",
       "      <td>2444.163872</td>\n",
       "      <td>1994.378469</td>\n",
       "      <td>2405.037231</td>\n",
       "      <td>1955.960378</td>\n",
       "      <td>2498.758759</td>\n",
       "      <td>1947.145678</td>\n",
       "      <td>2534.302185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Z</td>\n",
       "      <td>646.825790</td>\n",
       "      <td>1212.169051</td>\n",
       "      <td>674.274445</td>\n",
       "      <td>1242.027044</td>\n",
       "      <td>843.870282</td>\n",
       "      <td>1261.058211</td>\n",
       "      <td>1057.972789</td>\n",
       "      <td>1293.666124</td>\n",
       "      <td>1220.292091</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.024076</td>\n",
       "      <td>1216.723204</td>\n",
       "      <td>1082.362056</td>\n",
       "      <td>1026.123166</td>\n",
       "      <td>1191.763639</td>\n",
       "      <td>1050.326347</td>\n",
       "      <td>1154.398918</td>\n",
       "      <td>1090.296507</td>\n",
       "      <td>1120.047092</td>\n",
       "      <td>1066.013694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Z</td>\n",
       "      <td>742.793560</td>\n",
       "      <td>1290.448785</td>\n",
       "      <td>756.768525</td>\n",
       "      <td>1313.876748</td>\n",
       "      <td>911.147416</td>\n",
       "      <td>1330.813885</td>\n",
       "      <td>1126.545787</td>\n",
       "      <td>1361.523628</td>\n",
       "      <td>1301.351786</td>\n",
       "      <td>...</td>\n",
       "      <td>1108.314395</td>\n",
       "      <td>1289.618134</td>\n",
       "      <td>1201.952457</td>\n",
       "      <td>1120.719910</td>\n",
       "      <td>1311.442971</td>\n",
       "      <td>1128.456712</td>\n",
       "      <td>1273.124337</td>\n",
       "      <td>1169.704914</td>\n",
       "      <td>1245.737553</td>\n",
       "      <td>1152.362823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_type       wristX       wristY   thumb_CmcX   thumb_CmcY  \\\n",
       "0            A  1595.475198  1713.882845  1371.011287  1654.651115   \n",
       "1            A   719.049096  1577.525616   508.609653  1392.832041   \n",
       "2            A   757.780492  1601.105571   552.570701  1429.801345   \n",
       "3            A   615.760669  1031.698437   546.501115  1009.297512   \n",
       "4            A   322.910583  3155.554688   387.274112  3209.536560   \n",
       "..         ...          ...          ...          ...          ...   \n",
       "199          Z   758.030560  2493.725372   555.423833  2410.149605   \n",
       "200          Z  2576.749849  2868.969537  2432.240124  2800.074300   \n",
       "201          Z  1902.547185  2725.740898  1779.595316  2662.946720   \n",
       "202          Z   646.825790  1212.169051   674.274445  1242.027044   \n",
       "203          Z   742.793560  1290.448785   756.768525  1313.876748   \n",
       "\n",
       "      thumb_McpX   thumb_McpY    thumb_IpX    thumb_IpY   thumb_TipX  ...  \\\n",
       "0    1140.459070  1461.532063  1041.989141  1233.009396  1109.759125  ...   \n",
       "1     435.399145  1078.577757   453.572810   842.452109   486.912608  ...   \n",
       "2     481.703639  1114.173293   499.344498   878.003299   518.134713  ...   \n",
       "3     496.653780   939.493802   477.223635   880.857238   457.223967  ...   \n",
       "4     392.819341  3277.465576   393.364716  3335.383026   401.043561  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "199   554.325989  2121.368992   785.251643  1939.650558  1009.190364  ...   \n",
       "200  2270.718741  2749.498940  2145.062299  2784.001738  2058.201814  ...   \n",
       "201  1690.045661  2521.979805  1711.686770  2370.669079  1794.469457  ...   \n",
       "202   843.870282  1261.058211  1057.972789  1293.666124  1220.292091  ...   \n",
       "203   911.147416  1330.813885  1126.545787  1361.523628  1301.351786  ...   \n",
       "\n",
       "       ring_TipX    ring_TipY   pinky_McpX   pinky_McpY   pinky_PipX  \\\n",
       "0    1564.787345  1370.234713  1741.941414  1206.933278  1664.283545   \n",
       "1     843.840003  1323.482871  1090.264320  1240.741253  1128.179789   \n",
       "2     877.598047  1347.837567  1113.693476  1258.446693  1158.711910   \n",
       "3     606.932983   927.758379   666.484147   879.113685   633.975327   \n",
       "4     311.369056  3373.221863   272.978125  3264.753571   278.960250   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "199   836.804911  1998.270870   878.059498  1776.177761  1103.563620   \n",
       "200  2296.587610  2895.431664  2441.918750  2826.890079  2278.390603   \n",
       "201  1875.205433  2507.626522  2008.996679  2444.163872  1994.378469   \n",
       "202  1005.024076  1216.723204  1082.362056  1026.123166  1191.763639   \n",
       "203  1108.314395  1289.618134  1201.952457  1120.719910  1311.442971   \n",
       "\n",
       "      pinky_PipY   pinky_DipX   pinky_DipY   pinky_TipX   pinky_TipY  \n",
       "0    1119.481146  1645.726819  1310.211016  1689.494687  1349.412327  \n",
       "1    1106.518865  1024.695754  1242.374778   977.687418  1327.082992  \n",
       "2    1131.860495  1060.676217  1270.025492  1010.870814  1352.582455  \n",
       "3     843.605268   628.140047   895.670514   643.053487   913.554010  \n",
       "4    3301.982941   294.675690  3319.776947   307.635242  3325.865021  \n",
       "..           ...          ...          ...          ...          ...  \n",
       "199  1768.856277  1011.302115  1940.822914   882.944364  1985.800049  \n",
       "200  2947.817417  2309.023933  2981.885049  2355.511651  2958.717896  \n",
       "201  2405.037231  1955.960378  2498.758759  1947.145678  2534.302185  \n",
       "202  1050.326347  1154.398918  1090.296507  1120.047092  1066.013694  \n",
       "203  1128.456712  1273.124337  1169.704914  1245.737553  1152.362823  \n",
       "\n",
       "[204 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file for Validation or Testing the Model using Pandas\n",
    "df_test = pd.read_csv(\"hands_SIBI_validation.csv\", header=0)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "favorite-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Categorical using Pandas\n",
    "df_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\n",
    "df_train[\"class_type\"] = df_train.class_type.cat.codes\n",
    "\n",
    "df_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\n",
    "df_test[\"class_type\"] = df_test.class_type.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "associate-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Label and Feature for training\n",
    "y_train = df_train.pop(\"class_type\")\n",
    "x_train = df_train.copy()\n",
    "\n",
    "y_test = df_test.pop(\"class_type\")\n",
    "x_test = df_test.copy()\n",
    "\n",
    "# Copied Features turn to Array by using NumPy\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suburban-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 42)\n",
      "(204, 42)\n",
      "(1033, 42, 1)\n",
      "(204, 42, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check Array Shape before transformation\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Since the array shape is 1x1, we must turn it into 1x10x1 so we can feed it into the model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Check Array Shape after transformation\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "varied-patent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[614.664]\n",
      " [905.807]\n",
      " [549.962]\n",
      " [910.559]\n",
      " [484.506]\n",
      " [895.301]\n",
      " [446.416]\n",
      " [872.791]\n",
      " [435.599]\n",
      " [842.709]\n",
      " [492.176]\n",
      " [845.125]\n",
      " [455.925]\n",
      " [844.86 ]\n",
      " [478.732]\n",
      " [890.223]\n",
      " [501.187]\n",
      " [922.558]\n",
      " [536.641]\n",
      " [826.821]\n",
      " [510.607]\n",
      " [840.276]\n",
      " [530.386]\n",
      " [889.723]\n",
      " [550.536]\n",
      " [916.596]\n",
      " [581.733]\n",
      " [822.1  ]\n",
      " [561.356]\n",
      " [835.389]\n",
      " [580.989]\n",
      " [882.792]\n",
      " [597.934]\n",
      " [906.573]\n",
      " [621.966]\n",
      " [825.803]\n",
      " [617.01 ]\n",
      " [835.676]\n",
      " [628.267]\n",
      " [863.72 ]\n",
      " [636.858]\n",
      " [880.356]]\n",
      "[[2667.218]\n",
      " [1947.497]\n",
      " [2643.249]\n",
      " [1810.535]\n",
      " [2597.547]\n",
      " [1667.531]\n",
      " [2558.04 ]\n",
      " [1543.697]\n",
      " [2516.062]\n",
      " [1443.765]\n",
      " [2626.635]\n",
      " [1594.4  ]\n",
      " [2726.339]\n",
      " [1509.7  ]\n",
      " [2755.825]\n",
      " [1631.71 ]\n",
      " [2742.401]\n",
      " [1712.601]\n",
      " [2634.353]\n",
      " [1601.582]\n",
      " [2737.23 ]\n",
      " [1524.637]\n",
      " [2755.177]\n",
      " [1665.086]\n",
      " [2742.176]\n",
      " [1736.505]\n",
      " [2640.166]\n",
      " [1617.782]\n",
      " [2727.282]\n",
      " [1520.309]\n",
      " [2741.725]\n",
      " [1637.303]\n",
      " [2723.755]\n",
      " [1704.204]\n",
      " [2640.379]\n",
      " [1641.465]\n",
      " [2662.197]\n",
      " [1533.31 ]\n",
      " [2656.062]\n",
      " [1516.998]\n",
      " [2638.775]\n",
      " [1495.61 ]]\n"
     ]
    }
   ],
   "source": [
    "# Check sample train and test features\n",
    "print(x_train[0])\n",
    "print(x_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defined-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes according standard Alphabets\n",
    "num_classes = 26\n",
    "\n",
    "# Using the Keras.Utils to put the label categorically \n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tropical-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 40, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 18, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 1,292,570\n",
      "Trainable params: 1,292,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"relu\", input_shape=x_train.shape[1:3]),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "  tf.keras.layers.Conv1D(256, kernel_size=3, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "  # Flatten the results to feed into a DNN\n",
    "  tf.keras.layers.Flatten(), \n",
    "  # 512 neuron hidden layer\n",
    "  tf.keras.layers.Dense(512, activation='relu'), \n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ideal-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 108.8039 - accuracy: 0.0375 - val_loss: 3.2437 - val_accuracy: 0.0441\n",
      "Epoch 2/500\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 3.0661 - accuracy: 0.1217 - val_loss: 2.7820 - val_accuracy: 0.1667\n",
      "Epoch 3/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 2.5933 - accuracy: 0.2166 - val_loss: 2.3474 - val_accuracy: 0.2500\n",
      "Epoch 4/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.9939 - accuracy: 0.3981 - val_loss: 2.1287 - val_accuracy: 0.3775\n",
      "Epoch 5/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.7617 - accuracy: 0.4621 - val_loss: 1.8342 - val_accuracy: 0.4559\n",
      "Epoch 6/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.4978 - accuracy: 0.5624 - val_loss: 2.0176 - val_accuracy: 0.3873\n",
      "Epoch 7/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.5075 - accuracy: 0.5486 - val_loss: 1.7208 - val_accuracy: 0.4755\n",
      "Epoch 8/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.3903 - accuracy: 0.5710 - val_loss: 1.6832 - val_accuracy: 0.4902\n",
      "Epoch 9/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.2427 - accuracy: 0.6702 - val_loss: 1.4319 - val_accuracy: 0.5735\n",
      "Epoch 10/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.1478 - accuracy: 0.6628 - val_loss: 1.4871 - val_accuracy: 0.5490\n",
      "Epoch 11/500\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 1.1282 - accuracy: 0.6649 - val_loss: 1.3519 - val_accuracy: 0.6373\n",
      "Epoch 12/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.0736 - accuracy: 0.6885 - val_loss: 1.4849 - val_accuracy: 0.5294\n",
      "Epoch 13/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.2012 - accuracy: 0.6371 - val_loss: 1.4843 - val_accuracy: 0.5441\n",
      "Epoch 14/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 1.4048 - accuracy: 0.5710 - val_loss: 1.5181 - val_accuracy: 0.5343\n",
      "Epoch 15/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.1431 - accuracy: 0.6425 - val_loss: 1.4665 - val_accuracy: 0.5735\n",
      "Epoch 16/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 1.0825 - accuracy: 0.6713 - val_loss: 1.3884 - val_accuracy: 0.5735\n",
      "Epoch 17/500\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.0190 - accuracy: 0.6862 - val_loss: 1.4151 - val_accuracy: 0.5735\n",
      "Epoch 18/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 1.0402 - accuracy: 0.6745 - val_loss: 1.4621 - val_accuracy: 0.5735\n",
      "Epoch 19/500\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.9884 - accuracy: 0.7076 - val_loss: 1.3004 - val_accuracy: 0.6422\n",
      "Epoch 20/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.9353 - accuracy: 0.7097 - val_loss: 1.4972 - val_accuracy: 0.5441\n",
      "Epoch 21/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.9735 - accuracy: 0.6980 - val_loss: 1.4068 - val_accuracy: 0.6078\n",
      "Epoch 22/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.9294 - accuracy: 0.7172 - val_loss: 1.2967 - val_accuracy: 0.6029\n",
      "Epoch 23/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.9023 - accuracy: 0.7177 - val_loss: 1.3719 - val_accuracy: 0.5784\n",
      "Epoch 24/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.8961 - accuracy: 0.7268 - val_loss: 1.3547 - val_accuracy: 0.5931\n",
      "Epoch 25/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.8938 - accuracy: 0.7364 - val_loss: 1.4742 - val_accuracy: 0.5735\n",
      "Epoch 26/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.8508 - accuracy: 0.7225 - val_loss: 1.3474 - val_accuracy: 0.6471\n",
      "Epoch 27/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.9668 - accuracy: 0.7108 - val_loss: 1.3108 - val_accuracy: 0.6667\n",
      "Epoch 28/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.7279 - accuracy: 0.7631 - val_loss: 1.2765 - val_accuracy: 0.6471\n",
      "Epoch 29/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.8448 - accuracy: 0.7225 - val_loss: 1.4723 - val_accuracy: 0.6029\n",
      "Epoch 30/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.9404 - accuracy: 0.7086 - val_loss: 1.3343 - val_accuracy: 0.6029\n",
      "Epoch 31/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.7235 - accuracy: 0.7994 - val_loss: 1.3176 - val_accuracy: 0.6520\n",
      "Epoch 32/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.7350 - accuracy: 0.7684 - val_loss: 1.3003 - val_accuracy: 0.6373\n",
      "Epoch 33/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.7266 - accuracy: 0.7716 - val_loss: 1.4067 - val_accuracy: 0.5784\n",
      "Epoch 34/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.7718 - accuracy: 0.7427 - val_loss: 1.2659 - val_accuracy: 0.6373\n",
      "Epoch 35/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.7145 - accuracy: 0.7780 - val_loss: 1.3019 - val_accuracy: 0.6275\n",
      "Epoch 36/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6318 - accuracy: 0.8079 - val_loss: 1.3180 - val_accuracy: 0.6569\n",
      "Epoch 37/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.7377 - accuracy: 0.7716 - val_loss: 1.5879 - val_accuracy: 0.5833\n",
      "Epoch 38/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.8720 - accuracy: 0.7567 - val_loss: 1.5007 - val_accuracy: 0.6275\n",
      "Epoch 39/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.7394 - accuracy: 0.7673 - val_loss: 1.2531 - val_accuracy: 0.7010\n",
      "Epoch 40/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6502 - accuracy: 0.79 - 1s 24ms/step - loss: 0.6502 - accuracy: 0.7994 - val_loss: 1.2262 - val_accuracy: 0.7108\n",
      "Epoch 41/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.9363 - accuracy: 0.7108 - val_loss: 1.6762 - val_accuracy: 0.5588\n",
      "Epoch 42/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.7854 - accuracy: 0.7417 - val_loss: 1.4984 - val_accuracy: 0.6127\n",
      "Epoch 43/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6979 - accuracy: 0.8015 - val_loss: 1.4407 - val_accuracy: 0.5931\n",
      "Epoch 44/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.7758 - accuracy: 0.7631 - val_loss: 1.3556 - val_accuracy: 0.6471\n",
      "Epoch 45/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6433 - accuracy: 0.7969 - val_loss: 1.4037 - val_accuracy: 0.6275\n",
      "Epoch 46/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.5960 - accuracy: 0.8090 - val_loss: 1.3910 - val_accuracy: 0.6373\n",
      "Epoch 47/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5693 - accuracy: 0.8196 - val_loss: 1.4697 - val_accuracy: 0.6618\n",
      "Epoch 48/500\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5051 - accuracy: 0.8623 - val_loss: 1.2122 - val_accuracy: 0.6912\n",
      "Epoch 49/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6216 - accuracy: 0.7994 - val_loss: 1.4109 - val_accuracy: 0.6176\n",
      "Epoch 50/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5310 - accuracy: 0.8250 - val_loss: 1.3705 - val_accuracy: 0.6716\n",
      "Epoch 51/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5965 - accuracy: 0.8079 - val_loss: 1.3500 - val_accuracy: 0.6716\n",
      "Epoch 52/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5327 - accuracy: 0.8346 - val_loss: 1.4168 - val_accuracy: 0.6471\n",
      "Epoch 53/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.5087 - accuracy: 0.8442 - val_loss: 1.2167 - val_accuracy: 0.7010\n",
      "Epoch 54/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4978 - accuracy: 0.8442 - val_loss: 1.4239 - val_accuracy: 0.6765\n",
      "Epoch 55/500\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.6170 - accuracy: 0.8090 - val_loss: 1.8598 - val_accuracy: 0.6324\n",
      "Epoch 56/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.7045 - accuracy: 0.7792 - val_loss: 1.5935 - val_accuracy: 0.6422\n",
      "Epoch 57/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6955 - accuracy: 0.7716 - val_loss: 1.3931 - val_accuracy: 0.6814\n",
      "Epoch 58/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5186 - accuracy: 0.8410 - val_loss: 1.3121 - val_accuracy: 0.6716\n",
      "Epoch 59/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5720 - accuracy: 0.8175 - val_loss: 1.3718 - val_accuracy: 0.6814\n",
      "Epoch 60/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3927 - accuracy: 0.8815 - val_loss: 1.3522 - val_accuracy: 0.7010\n",
      "Epoch 61/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4715 - accuracy: 0.8613 - val_loss: 1.3815 - val_accuracy: 0.7353\n",
      "Epoch 62/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6221 - accuracy: 0.7930 - val_loss: 1.7332 - val_accuracy: 0.5735\n",
      "Epoch 63/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.7785 - accuracy: 0.7663 - val_loss: 1.5146 - val_accuracy: 0.6373\n",
      "Epoch 64/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6579 - accuracy: 0.7769 - val_loss: 1.4391 - val_accuracy: 0.6520\n",
      "Epoch 65/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.5537 - accuracy: 0.8228 - val_loss: 1.2979 - val_accuracy: 0.7010\n",
      "Epoch 66/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4729 - accuracy: 0.8335 - val_loss: 1.4599 - val_accuracy: 0.6618\n",
      "Epoch 67/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3864 - accuracy: 0.8781 - val_loss: 1.4131 - val_accuracy: 0.6912\n",
      "Epoch 68/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4344 - accuracy: 0.8613 - val_loss: 1.4559 - val_accuracy: 0.7059\n",
      "Epoch 69/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3800 - accuracy: 0.8837 - val_loss: 1.6032 - val_accuracy: 0.6863\n",
      "Epoch 70/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4204 - accuracy: 0.8730 - val_loss: 1.6969 - val_accuracy: 0.6422\n",
      "Epoch 71/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.5210 - accuracy: 0.8335 - val_loss: 1.6298 - val_accuracy: 0.6520\n",
      "Epoch 72/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4435 - accuracy: 0.8602 - val_loss: 1.5026 - val_accuracy: 0.6716\n",
      "Epoch 73/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4705 - accuracy: 0.8527 - val_loss: 1.7839 - val_accuracy: 0.6324\n",
      "Epoch 74/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6089 - accuracy: 0.8090 - val_loss: 1.4861 - val_accuracy: 0.6716\n",
      "Epoch 75/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4426 - accuracy: 0.8559 - val_loss: 1.5350 - val_accuracy: 0.6765\n",
      "Epoch 76/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3536 - accuracy: 0.8879 - val_loss: 1.2483 - val_accuracy: 0.7353\n",
      "Epoch 77/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3106 - accuracy: 0.9018 - val_loss: 1.4325 - val_accuracy: 0.7206\n",
      "Epoch 78/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3172 - accuracy: 0.8958 - val_loss: 1.4775 - val_accuracy: 0.7206\n",
      "Epoch 79/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4015 - accuracy: 0.8666 - val_loss: 1.6658 - val_accuracy: 0.6520\n",
      "Epoch 80/500\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.4374 - accuracy: 0.8538 - val_loss: 1.5261 - val_accuracy: 0.7304\n",
      "Epoch 81/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4803 - accuracy: 0.8388 - val_loss: 1.6701 - val_accuracy: 0.6569\n",
      "Epoch 82/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.4876 - accuracy: 0.8399 - val_loss: 1.5244 - val_accuracy: 0.7059\n",
      "Epoch 83/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6027 - accuracy: 0.8122 - val_loss: 1.8938 - val_accuracy: 0.6618\n",
      "Epoch 84/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5326 - accuracy: 0.8314 - val_loss: 1.5847 - val_accuracy: 0.7010\n",
      "Epoch 85/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3970 - accuracy: 0.8549 - val_loss: 1.7582 - val_accuracy: 0.6765\n",
      "Epoch 86/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.4953 - accuracy: 0.8410 - val_loss: 1.8236 - val_accuracy: 0.6667\n",
      "Epoch 87/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5828 - accuracy: 0.8186 - val_loss: 1.6048 - val_accuracy: 0.6471\n",
      "Epoch 88/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.7277 - accuracy: 0.8367 - val_loss: 1.3850 - val_accuracy: 0.6912\n",
      "Epoch 89/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4642 - accuracy: 0.8615 - val_loss: 1.7003 - val_accuracy: 0.6863\n",
      "Epoch 90/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.7222 - accuracy: 0.8047 - val_loss: 1.5271 - val_accuracy: 0.6912\n",
      "Epoch 91/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4783 - accuracy: 0.8463 - val_loss: 1.5429 - val_accuracy: 0.7010\n",
      "Epoch 92/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4123 - accuracy: 0.8687 - val_loss: 1.5993 - val_accuracy: 0.6618\n",
      "Epoch 93/500\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3630 - accuracy: 0.8954 - val_loss: 1.4280 - val_accuracy: 0.7353\n",
      "Epoch 94/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2568 - accuracy: 0.9189 - val_loss: 1.5093 - val_accuracy: 0.7157\n",
      "Epoch 95/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3743 - accuracy: 0.8773 - val_loss: 2.0344 - val_accuracy: 0.6176\n",
      "Epoch 96/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3621 - accuracy: 0.8858 - val_loss: 1.4373 - val_accuracy: 0.7255\n",
      "Epoch 97/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2978 - accuracy: 0.9061 - val_loss: 1.6334 - val_accuracy: 0.6863\n",
      "Epoch 98/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3685 - accuracy: 0.8815 - val_loss: 1.4779 - val_accuracy: 0.7304\n",
      "Epoch 99/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3425 - accuracy: 0.8826 - val_loss: 1.7569 - val_accuracy: 0.7206\n",
      "Epoch 100/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3962 - accuracy: 0.8760 - val_loss: 1.5910 - val_accuracy: 0.7500\n",
      "Epoch 101/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3017 - accuracy: 0.9018 - val_loss: 1.7862 - val_accuracy: 0.6814\n",
      "Epoch 102/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3221 - accuracy: 0.8922 - val_loss: 1.5480 - val_accuracy: 0.7059\n",
      "Epoch 103/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2557 - accuracy: 0.9221 - val_loss: 1.5086 - val_accuracy: 0.7304\n",
      "Epoch 104/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3613 - accuracy: 0.8837 - val_loss: 1.7290 - val_accuracy: 0.7059\n",
      "Epoch 105/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3019 - accuracy: 0.8997 - val_loss: 1.9770 - val_accuracy: 0.6373\n",
      "Epoch 106/500\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.3017 - accuracy: 0.8997 - val_loss: 1.7633 - val_accuracy: 0.7059\n",
      "Epoch 107/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2768 - accuracy: 0.9072 - val_loss: 1.7351 - val_accuracy: 0.7255\n",
      "Epoch 108/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2273 - accuracy: 0.9210 - val_loss: 1.5933 - val_accuracy: 0.7451\n",
      "Epoch 109/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2688 - accuracy: 0.9168 - val_loss: 1.7459 - val_accuracy: 0.7206\n",
      "Epoch 110/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2888 - accuracy: 0.9072 - val_loss: 2.0337 - val_accuracy: 0.6863\n",
      "Epoch 111/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2417 - accuracy: 0.9208 - val_loss: 1.6173 - val_accuracy: 0.7598\n",
      "Epoch 112/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5593 - accuracy: 0.8367 - val_loss: 2.2387 - val_accuracy: 0.6569\n",
      "Epoch 113/500\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6308 - accuracy: 0.8111 - val_loss: 2.1454 - val_accuracy: 0.6520\n",
      "Epoch 114/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4288 - accuracy: 0.8591 - val_loss: 1.5377 - val_accuracy: 0.7108\n",
      "Epoch 115/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3325 - accuracy: 0.8858 - val_loss: 1.5011 - val_accuracy: 0.7451\n",
      "Epoch 116/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2799 - accuracy: 0.9178 - val_loss: 1.6426 - val_accuracy: 0.7255\n",
      "Epoch 117/500\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.2151 - accuracy: 0.9338 - val_loss: 1.5828 - val_accuracy: 0.7451\n",
      "Epoch 118/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2664 - accuracy: 0.9210 - val_loss: 1.8387 - val_accuracy: 0.7304\n",
      "Epoch 119/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.2349 - accuracy: 0.9232 - val_loss: 1.6172 - val_accuracy: 0.7549\n",
      "Epoch 120/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2267 - accuracy: 0.9285 - val_loss: 1.7685 - val_accuracy: 0.7402\n",
      "Epoch 121/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2336 - accuracy: 0.9253 - val_loss: 1.6069 - val_accuracy: 0.7451\n",
      "Epoch 122/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2466 - accuracy: 0.9104 - val_loss: 1.8842 - val_accuracy: 0.7304\n",
      "Epoch 123/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2956 - accuracy: 0.9146 - val_loss: 2.1752 - val_accuracy: 0.6716\n",
      "Epoch 124/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5265 - accuracy: 0.8420 - val_loss: 2.2491 - val_accuracy: 0.6029\n",
      "Epoch 125/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4956 - accuracy: 0.8474 - val_loss: 1.6501 - val_accuracy: 0.7255\n",
      "Epoch 126/500\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.3116 - accuracy: 0.8954 - val_loss: 1.8336 - val_accuracy: 0.7059\n",
      "Epoch 127/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3346 - accuracy: 0.8933 - val_loss: 2.0081 - val_accuracy: 0.7108\n",
      "Epoch 128/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2639 - accuracy: 0.9093 - val_loss: 1.7000 - val_accuracy: 0.7451\n",
      "Epoch 129/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2788 - accuracy: 0.9136 - val_loss: 1.7472 - val_accuracy: 0.7500\n",
      "Epoch 130/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2690 - accuracy: 0.9093 - val_loss: 1.8068 - val_accuracy: 0.7549\n",
      "Epoch 131/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3400 - accuracy: 0.9018 - val_loss: 2.7836 - val_accuracy: 0.6275\n",
      "Epoch 132/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5610 - accuracy: 0.8410 - val_loss: 1.9509 - val_accuracy: 0.7255\n",
      "Epoch 133/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6545 - accuracy: 0.8344 - val_loss: 1.8516 - val_accuracy: 0.7451\n",
      "Epoch 134/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3775 - accuracy: 0.8837 - val_loss: 1.8871 - val_accuracy: 0.7402\n",
      "Epoch 135/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2433 - accuracy: 0.9285 - val_loss: 1.6591 - val_accuracy: 0.7598\n",
      "Epoch 136/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4840 - accuracy: 0.8655 - val_loss: 1.7448 - val_accuracy: 0.7353\n",
      "Epoch 137/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3391 - accuracy: 0.8965 - val_loss: 1.7990 - val_accuracy: 0.7353\n",
      "Epoch 138/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2915 - accuracy: 0.9157 - val_loss: 1.8051 - val_accuracy: 0.7157\n",
      "Epoch 139/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.3200 - accuracy: 0.8933 - val_loss: 2.1329 - val_accuracy: 0.7059\n",
      "Epoch 140/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1980 - accuracy: 0.9402 - val_loss: 1.7303 - val_accuracy: 0.7549\n",
      "Epoch 141/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1961 - accuracy: 0.9402 - val_loss: 1.6478 - val_accuracy: 0.7647\n",
      "Epoch 142/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1817 - accuracy: 0.9509 - val_loss: 1.6462 - val_accuracy: 0.7696\n",
      "Epoch 143/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1781 - accuracy: 0.9456 - val_loss: 1.8506 - val_accuracy: 0.7451\n",
      "Epoch 144/500\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.2026 - accuracy: 0.9323 - val_loss: 1.7940 - val_accuracy: 0.7304\n",
      "Epoch 145/500\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.1826 - accuracy: 0.9381 - val_loss: 1.8773 - val_accuracy: 0.7500\n",
      "Epoch 146/500\n",
      "30/30 [==============================] - 1s 46ms/step - loss: 0.3119 - accuracy: 0.9114 - val_loss: 2.0898 - val_accuracy: 0.7206\n",
      "Epoch 147/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.7613 - accuracy: 0.8090 - val_loss: 2.6008 - val_accuracy: 0.6716\n",
      "Epoch 148/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6981 - accuracy: 0.8175 - val_loss: 2.3637 - val_accuracy: 0.6324\n",
      "Epoch 149/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3895 - accuracy: 0.8879 - val_loss: 1.6278 - val_accuracy: 0.7010\n",
      "Epoch 150/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2862 - accuracy: 0.9125 - val_loss: 1.7576 - val_accuracy: 0.7500\n",
      "Epoch 151/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2192 - accuracy: 0.9306 - val_loss: 1.7596 - val_accuracy: 0.7500\n",
      "Epoch 152/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1927 - accuracy: 0.9456 - val_loss: 1.6530 - val_accuracy: 0.7500\n",
      "Epoch 153/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1620 - accuracy: 0.9530 - val_loss: 1.5821 - val_accuracy: 0.7500\n",
      "Epoch 154/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1542 - accuracy: 0.9541 - val_loss: 1.9156 - val_accuracy: 0.7353\n",
      "Epoch 155/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1846 - accuracy: 0.9406 - val_loss: 1.7586 - val_accuracy: 0.7500\n",
      "Epoch 156/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1747 - accuracy: 0.9445 - val_loss: 1.7391 - val_accuracy: 0.7402\n",
      "Epoch 157/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1423 - accuracy: 0.9562 - val_loss: 1.8604 - val_accuracy: 0.7402\n",
      "Epoch 158/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1624 - accuracy: 0.9541 - val_loss: 1.8368 - val_accuracy: 0.7451\n",
      "Epoch 159/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1351 - accuracy: 0.9605 - val_loss: 1.7308 - val_accuracy: 0.7598\n",
      "Epoch 160/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1555 - accuracy: 0.9520 - val_loss: 1.9243 - val_accuracy: 0.7549\n",
      "Epoch 161/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1327 - accuracy: 0.9669 - val_loss: 1.8797 - val_accuracy: 0.7549\n",
      "Epoch 162/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1496 - accuracy: 0.9552 - val_loss: 1.7553 - val_accuracy: 0.7696\n",
      "Epoch 163/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1712 - accuracy: 0.9488 - val_loss: 2.1790 - val_accuracy: 0.7255\n",
      "Epoch 164/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2212 - accuracy: 0.9392 - val_loss: 1.8641 - val_accuracy: 0.7500\n",
      "Epoch 165/500\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.2201 - accuracy: 0.9349 - val_loss: 2.2905 - val_accuracy: 0.7353\n",
      "Epoch 166/500\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.1927 - accuracy: 0.9375 - val_loss: 1.8818 - val_accuracy: 0.7745\n",
      "Epoch 167/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1633 - accuracy: 0.9520 - val_loss: 1.6436 - val_accuracy: 0.7451\n",
      "Epoch 168/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3589 - accuracy: 0.8986 - val_loss: 2.3692 - val_accuracy: 0.7059\n",
      "Epoch 169/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3035 - accuracy: 0.9104 - val_loss: 1.6970 - val_accuracy: 0.7500\n",
      "Epoch 170/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4180 - accuracy: 0.8719 - val_loss: 1.9086 - val_accuracy: 0.7157\n",
      "Epoch 171/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2416 - accuracy: 0.9242 - val_loss: 2.0197 - val_accuracy: 0.7451\n",
      "Epoch 172/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2945 - accuracy: 0.9114 - val_loss: 1.8985 - val_accuracy: 0.7500\n",
      "Epoch 173/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2242 - accuracy: 0.9328 - val_loss: 1.9588 - val_accuracy: 0.7304\n",
      "Epoch 174/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1862 - accuracy: 0.9456 - val_loss: 1.8085 - val_accuracy: 0.7598\n",
      "Epoch 175/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1892 - accuracy: 0.9381 - val_loss: 1.8114 - val_accuracy: 0.7451\n",
      "Epoch 176/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1477 - accuracy: 0.9488 - val_loss: 1.8843 - val_accuracy: 0.7451\n",
      "Epoch 177/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1476 - accuracy: 0.9510 - val_loss: 1.6874 - val_accuracy: 0.7794\n",
      "Epoch 178/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1287 - accuracy: 0.9605 - val_loss: 1.8751 - val_accuracy: 0.7745\n",
      "Epoch 179/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1426 - accuracy: 0.9552 - val_loss: 1.8802 - val_accuracy: 0.7647\n",
      "Epoch 180/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1324 - accuracy: 0.9605 - val_loss: 1.8094 - val_accuracy: 0.7549\n",
      "Epoch 181/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1160 - accuracy: 0.9626 - val_loss: 1.7759 - val_accuracy: 0.7794\n",
      "Epoch 182/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1726 - accuracy: 0.9413 - val_loss: 1.7340 - val_accuracy: 0.7794\n",
      "Epoch 183/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1903 - accuracy: 0.9456 - val_loss: 2.3858 - val_accuracy: 0.7353\n",
      "Epoch 184/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1698 - accuracy: 0.9424 - val_loss: 2.1087 - val_accuracy: 0.7451\n",
      "Epoch 185/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.2671 - accuracy: 0.9136 - val_loss: 2.0388 - val_accuracy: 0.7549\n",
      "Epoch 186/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.2776 - accuracy: 0.9178 - val_loss: 2.3136 - val_accuracy: 0.7206\n",
      "Epoch 187/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4568 - accuracy: 0.8751 - val_loss: 2.6688 - val_accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4856 - accuracy: 0.8583 - val_loss: 2.8277 - val_accuracy: 0.6814\n",
      "Epoch 189/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4635 - accuracy: 0.8762 - val_loss: 2.0583 - val_accuracy: 0.7500\n",
      "Epoch 190/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2919 - accuracy: 0.9104 - val_loss: 1.8540 - val_accuracy: 0.7647\n",
      "Epoch 191/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2293 - accuracy: 0.9349 - val_loss: 1.7570 - val_accuracy: 0.7647\n",
      "Epoch 192/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2166 - accuracy: 0.9285 - val_loss: 1.8525 - val_accuracy: 0.7500\n",
      "Epoch 193/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2970 - accuracy: 0.9093 - val_loss: 2.1781 - val_accuracy: 0.7206\n",
      "Epoch 194/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.3154 - accuracy: 0.9007 - val_loss: 2.0634 - val_accuracy: 0.7206\n",
      "Epoch 195/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1967 - accuracy: 0.9381 - val_loss: 1.9064 - val_accuracy: 0.7647\n",
      "Epoch 196/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1716 - accuracy: 0.9445 - val_loss: 1.7560 - val_accuracy: 0.7500\n",
      "Epoch 197/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 1.9444 - val_accuracy: 0.7500\n",
      "Epoch 198/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1293 - accuracy: 0.9594 - val_loss: 2.0057 - val_accuracy: 0.7647\n",
      "Epoch 199/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1191 - accuracy: 0.9635 - val_loss: 1.9281 - val_accuracy: 0.7598\n",
      "Epoch 200/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1040 - accuracy: 0.9691 - val_loss: 1.8486 - val_accuracy: 0.7696\n",
      "Epoch 201/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1023 - accuracy: 0.9680 - val_loss: 1.8721 - val_accuracy: 0.7647\n",
      "Epoch 202/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1224 - accuracy: 0.9626 - val_loss: 1.9151 - val_accuracy: 0.7549\n",
      "Epoch 203/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1057 - accuracy: 0.9680 - val_loss: 1.9865 - val_accuracy: 0.7598\n",
      "Epoch 204/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1122 - accuracy: 0.9626 - val_loss: 1.9006 - val_accuracy: 0.7647\n",
      "Epoch 205/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0949 - accuracy: 0.9712 - val_loss: 1.9527 - val_accuracy: 0.7647\n",
      "Epoch 206/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1177 - accuracy: 0.9594 - val_loss: 2.1334 - val_accuracy: 0.7598\n",
      "Epoch 207/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1007 - accuracy: 0.9680 - val_loss: 2.0347 - val_accuracy: 0.7598\n",
      "Epoch 208/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0959 - accuracy: 0.9691 - val_loss: 1.9573 - val_accuracy: 0.7598\n",
      "Epoch 209/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1041 - accuracy: 0.9648 - val_loss: 1.9419 - val_accuracy: 0.7598\n",
      "Epoch 210/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0974 - accuracy: 0.9667 - val_loss: 1.9758 - val_accuracy: 0.7598\n",
      "Epoch 211/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0877 - accuracy: 0.9723 - val_loss: 2.0263 - val_accuracy: 0.7598\n",
      "Epoch 212/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0974 - accuracy: 0.9691 - val_loss: 2.1550 - val_accuracy: 0.7500\n",
      "Epoch 213/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1218 - accuracy: 0.9562 - val_loss: 2.0763 - val_accuracy: 0.7598\n",
      "Epoch 214/500\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 2.0977 - val_accuracy: 0.7598\n",
      "Epoch 215/500\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.0888 - accuracy: 0.9701 - val_loss: 2.0263 - val_accuracy: 0.7647\n",
      "Epoch 216/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1086 - accuracy: 0.9616 - val_loss: 2.0865 - val_accuracy: 0.7549\n",
      "Epoch 217/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0842 - accuracy: 0.9701 - val_loss: 2.0393 - val_accuracy: 0.7647\n",
      "Epoch 218/500\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.0900 - accuracy: 0.9691 - val_loss: 2.1029 - val_accuracy: 0.7647\n",
      "Epoch 219/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1034 - accuracy: 0.9637 - val_loss: 2.0957 - val_accuracy: 0.7598\n",
      "Epoch 220/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0938 - accuracy: 0.9669 - val_loss: 2.1368 - val_accuracy: 0.7598\n",
      "Epoch 221/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0904 - accuracy: 0.9667 - val_loss: 2.1332 - val_accuracy: 0.7647\n",
      "Epoch 222/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0925 - accuracy: 0.9669 - val_loss: 2.1186 - val_accuracy: 0.7598\n",
      "Epoch 223/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1007 - accuracy: 0.9648 - val_loss: 2.1480 - val_accuracy: 0.7598\n",
      "Epoch 224/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0777 - accuracy: 0.9723 - val_loss: 2.1645 - val_accuracy: 0.7647\n",
      "Epoch 225/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1008 - accuracy: 0.9637 - val_loss: 2.1851 - val_accuracy: 0.7647\n",
      "Epoch 226/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0867 - accuracy: 0.9701 - val_loss: 2.2025 - val_accuracy: 0.7549\n",
      "Epoch 227/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0906 - accuracy: 0.9680 - val_loss: 2.1809 - val_accuracy: 0.7549\n",
      "Epoch 228/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1047 - accuracy: 0.9637 - val_loss: 2.2209 - val_accuracy: 0.7647\n",
      "Epoch 229/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0787 - accuracy: 0.9723 - val_loss: 2.2129 - val_accuracy: 0.7500\n",
      "Epoch 230/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0976 - accuracy: 0.9637 - val_loss: 2.2213 - val_accuracy: 0.7598\n",
      "Epoch 231/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0896 - accuracy: 0.9658 - val_loss: 2.2441 - val_accuracy: 0.7598\n",
      "Epoch 232/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 2.2244 - val_accuracy: 0.7598\n",
      "Epoch 233/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0836 - accuracy: 0.9723 - val_loss: 2.2360 - val_accuracy: 0.7598\n",
      "Epoch 234/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0961 - accuracy: 0.9648 - val_loss: 2.2448 - val_accuracy: 0.7647\n",
      "Epoch 235/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0911 - accuracy: 0.9680 - val_loss: 2.2558 - val_accuracy: 0.7598\n",
      "Epoch 236/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0659 - accuracy: 0.9765 - val_loss: 2.2535 - val_accuracy: 0.7598\n",
      "Epoch 237/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1108 - accuracy: 0.9584 - val_loss: 2.2626 - val_accuracy: 0.7549\n",
      "Epoch 238/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1003 - accuracy: 0.9648 - val_loss: 2.2753 - val_accuracy: 0.7647\n",
      "Epoch 239/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0805 - accuracy: 0.9723 - val_loss: 2.2829 - val_accuracy: 0.7598\n",
      "Epoch 240/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1007 - accuracy: 0.9637 - val_loss: 2.3318 - val_accuracy: 0.7696\n",
      "Epoch 241/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0874 - accuracy: 0.9680 - val_loss: 2.3008 - val_accuracy: 0.7745\n",
      "Epoch 242/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0842 - accuracy: 0.9723 - val_loss: 2.3098 - val_accuracy: 0.7745\n",
      "Epoch 243/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0907 - accuracy: 0.9677 - val_loss: 2.3340 - val_accuracy: 0.7647\n",
      "Epoch 244/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0977 - accuracy: 0.9648 - val_loss: 2.2740 - val_accuracy: 0.7549\n",
      "Epoch 245/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 2.3374 - val_accuracy: 0.7647\n",
      "Epoch 246/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0955 - accuracy: 0.9680 - val_loss: 2.3476 - val_accuracy: 0.7647\n",
      "Epoch 247/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0729 - accuracy: 0.9755 - val_loss: 2.3564 - val_accuracy: 0.7696\n",
      "Epoch 248/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1097 - accuracy: 0.9605 - val_loss: 2.3690 - val_accuracy: 0.7696\n",
      "Epoch 249/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0870 - accuracy: 0.9691 - val_loss: 2.4078 - val_accuracy: 0.7598\n",
      "Epoch 250/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.8322 - accuracy: 0.8581 - val_loss: 3.8735 - val_accuracy: 0.6324\n",
      "Epoch 251/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 1.7599 - accuracy: 0.7150 - val_loss: 2.5060 - val_accuracy: 0.6520\n",
      "Epoch 252/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.8705 - accuracy: 0.7791 - val_loss: 2.3620 - val_accuracy: 0.5980\n",
      "Epoch 253/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.6470 - accuracy: 0.8036 - val_loss: 2.3470 - val_accuracy: 0.6765\n",
      "Epoch 254/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6671 - accuracy: 0.8135 - val_loss: 1.7297 - val_accuracy: 0.7304\n",
      "Epoch 255/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4682 - accuracy: 0.8495 - val_loss: 1.8412 - val_accuracy: 0.7353\n",
      "Epoch 256/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3538 - accuracy: 0.8815 - val_loss: 1.6330 - val_accuracy: 0.7549\n",
      "Epoch 257/500\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.3234 - accuracy: 0.9018 - val_loss: 1.6618 - val_accuracy: 0.7549\n",
      "Epoch 258/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2131 - accuracy: 0.9306 - val_loss: 1.6318 - val_accuracy: 0.7304\n",
      "Epoch 259/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2542 - accuracy: 0.9168 - val_loss: 1.8576 - val_accuracy: 0.7157\n",
      "Epoch 260/500\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1971 - accuracy: 0.9317 - val_loss: 1.6492 - val_accuracy: 0.7451\n",
      "Epoch 261/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1564 - accuracy: 0.9498 - val_loss: 2.2237 - val_accuracy: 0.7304\n",
      "Epoch 262/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2238 - accuracy: 0.9317 - val_loss: 1.7666 - val_accuracy: 0.7500\n",
      "Epoch 263/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2240 - accuracy: 0.9392 - val_loss: 1.7530 - val_accuracy: 0.7549\n",
      "Epoch 264/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1999 - accuracy: 0.9488 - val_loss: 1.9479 - val_accuracy: 0.7402\n",
      "Epoch 265/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1565 - accuracy: 0.9583 - val_loss: 1.7406 - val_accuracy: 0.7794\n",
      "Epoch 266/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1523 - accuracy: 0.9498 - val_loss: 1.6756 - val_accuracy: 0.7598\n",
      "Epoch 267/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1214 - accuracy: 0.9616 - val_loss: 1.7409 - val_accuracy: 0.7647\n",
      "Epoch 268/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1355 - accuracy: 0.9584 - val_loss: 1.8140 - val_accuracy: 0.7745\n",
      "Epoch 269/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1217 - accuracy: 0.9573 - val_loss: 1.9381 - val_accuracy: 0.7451\n",
      "Epoch 270/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1346 - accuracy: 0.9562 - val_loss: 1.9957 - val_accuracy: 0.7696\n",
      "Epoch 271/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1152 - accuracy: 0.9669 - val_loss: 1.9597 - val_accuracy: 0.7696\n",
      "Epoch 272/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1093 - accuracy: 0.9669 - val_loss: 1.9227 - val_accuracy: 0.7647\n",
      "Epoch 273/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1094 - accuracy: 0.9669 - val_loss: 1.8496 - val_accuracy: 0.7696\n",
      "Epoch 274/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1030 - accuracy: 0.9680 - val_loss: 1.8753 - val_accuracy: 0.7696\n",
      "Epoch 275/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0952 - accuracy: 0.9701 - val_loss: 1.8963 - val_accuracy: 0.7696\n",
      "Epoch 276/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 1.8845 - val_accuracy: 0.7696\n",
      "Epoch 277/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0988 - accuracy: 0.9691 - val_loss: 1.8954 - val_accuracy: 0.7696\n",
      "Epoch 278/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0898 - accuracy: 0.9712 - val_loss: 1.9063 - val_accuracy: 0.7745\n",
      "Epoch 279/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1129 - accuracy: 0.9616 - val_loss: 1.9050 - val_accuracy: 0.7647\n",
      "Epoch 280/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1231 - accuracy: 0.9562 - val_loss: 2.2423 - val_accuracy: 0.7402\n",
      "Epoch 281/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1467 - accuracy: 0.9530 - val_loss: 2.0182 - val_accuracy: 0.7500\n",
      "Epoch 282/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1433 - accuracy: 0.9509 - val_loss: 2.1454 - val_accuracy: 0.7794\n",
      "Epoch 283/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1704 - accuracy: 0.9424 - val_loss: 2.1632 - val_accuracy: 0.7549\n",
      "Epoch 284/500\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1546 - accuracy: 0.9509 - val_loss: 2.0453 - val_accuracy: 0.7549\n",
      "Epoch 285/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2440 - accuracy: 0.9264 - val_loss: 2.2669 - val_accuracy: 0.7598\n",
      "Epoch 286/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2021 - accuracy: 0.9285 - val_loss: 2.4161 - val_accuracy: 0.7304\n",
      "Epoch 287/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2041 - accuracy: 0.9323 - val_loss: 1.9758 - val_accuracy: 0.7598\n",
      "Epoch 288/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1742 - accuracy: 0.9402 - val_loss: 1.9195 - val_accuracy: 0.7598\n",
      "Epoch 289/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5451 - accuracy: 0.8687 - val_loss: 2.3732 - val_accuracy: 0.7108\n",
      "Epoch 290/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4059 - accuracy: 0.8890 - val_loss: 2.0678 - val_accuracy: 0.7353\n",
      "Epoch 291/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2533 - accuracy: 0.9178 - val_loss: 2.0674 - val_accuracy: 0.7451\n",
      "Epoch 292/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3021 - accuracy: 0.9039 - val_loss: 2.0616 - val_accuracy: 0.7500\n",
      "Epoch 293/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.5877 - accuracy: 0.8463 - val_loss: 2.2341 - val_accuracy: 0.6863\n",
      "Epoch 294/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5507 - accuracy: 0.8431 - val_loss: 2.1389 - val_accuracy: 0.7353\n",
      "Epoch 295/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6554 - accuracy: 0.8431 - val_loss: 2.3120 - val_accuracy: 0.6814\n",
      "Epoch 296/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6676 - accuracy: 0.8581 - val_loss: 2.0492 - val_accuracy: 0.6912\n",
      "Epoch 297/500\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6859 - accuracy: 0.8271 - val_loss: 2.0421 - val_accuracy: 0.7549\n",
      "Epoch 298/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3917 - accuracy: 0.8927 - val_loss: 2.0242 - val_accuracy: 0.7549\n",
      "Epoch 299/500\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.3057 - accuracy: 0.9072 - val_loss: 2.0546 - val_accuracy: 0.7451\n",
      "Epoch 300/500\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.2405 - accuracy: 0.9328 - val_loss: 2.1638 - val_accuracy: 0.7696\n",
      "Epoch 301/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2326 - accuracy: 0.9328 - val_loss: 2.0496 - val_accuracy: 0.7745\n",
      "Epoch 302/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2098 - accuracy: 0.9381 - val_loss: 2.1180 - val_accuracy: 0.7451\n",
      "Epoch 303/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1932 - accuracy: 0.9424 - val_loss: 2.2979 - val_accuracy: 0.7598\n",
      "Epoch 304/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1960 - accuracy: 0.9498 - val_loss: 2.0864 - val_accuracy: 0.7500\n",
      "Epoch 305/500\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1393 - accuracy: 0.9605 - val_loss: 1.9911 - val_accuracy: 0.7794\n",
      "Epoch 306/500\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.1671 - accuracy: 0.9541 - val_loss: 2.2909 - val_accuracy: 0.7549\n",
      "Epoch 307/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1653 - accuracy: 0.9520 - val_loss: 2.0380 - val_accuracy: 0.7696\n",
      "Epoch 308/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1605 - accuracy: 0.9562 - val_loss: 2.0248 - val_accuracy: 0.7745\n",
      "Epoch 309/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1723 - accuracy: 0.9552 - val_loss: 2.3788 - val_accuracy: 0.7451\n",
      "Epoch 310/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1711 - accuracy: 0.9498 - val_loss: 2.0952 - val_accuracy: 0.7794\n",
      "Epoch 311/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1599 - accuracy: 0.9530 - val_loss: 2.1976 - val_accuracy: 0.7745\n",
      "Epoch 312/500\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1017 - accuracy: 0.9744 - val_loss: 2.1434 - val_accuracy: 0.7794\n",
      "Epoch 313/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1110 - accuracy: 0.9712 - val_loss: 2.0373 - val_accuracy: 0.7843\n",
      "Epoch 314/500\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.1377 - accuracy: 0.9584 - val_loss: 2.1464 - val_accuracy: 0.7500\n",
      "Epoch 315/500\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.1688 - accuracy: 0.9530 - val_loss: 2.1310 - val_accuracy: 0.7745\n",
      "Epoch 316/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1386 - accuracy: 0.9594 - val_loss: 2.3900 - val_accuracy: 0.7598\n",
      "Epoch 317/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1166 - accuracy: 0.9680 - val_loss: 2.5224 - val_accuracy: 0.7745\n",
      "Epoch 318/500\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1558 - accuracy: 0.9616 - val_loss: 2.3705 - val_accuracy: 0.7549\n",
      "Epoch 319/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2011 - accuracy: 0.9381 - val_loss: 2.1410 - val_accuracy: 0.7745\n",
      "Epoch 320/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1343 - accuracy: 0.9646 - val_loss: 2.2015 - val_accuracy: 0.7745\n",
      "Epoch 321/500\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1167 - accuracy: 0.9669 - val_loss: 2.6073 - val_accuracy: 0.7402\n",
      "Epoch 322/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2930 - accuracy: 0.9328 - val_loss: 2.6347 - val_accuracy: 0.7500\n",
      "Epoch 323/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1606 - accuracy: 0.9616 - val_loss: 2.4361 - val_accuracy: 0.7647\n",
      "Epoch 324/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1247 - accuracy: 0.9573 - val_loss: 2.2294 - val_accuracy: 0.7941\n",
      "Epoch 325/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1181 - accuracy: 0.9723 - val_loss: 2.2450 - val_accuracy: 0.7696\n",
      "Epoch 326/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1199 - accuracy: 0.9658 - val_loss: 2.1357 - val_accuracy: 0.7990\n",
      "Epoch 327/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1302 - accuracy: 0.9616 - val_loss: 2.2970 - val_accuracy: 0.7892\n",
      "Epoch 328/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2112 - accuracy: 0.9434 - val_loss: 2.9717 - val_accuracy: 0.6814\n",
      "Epoch 329/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4145 - accuracy: 0.8943 - val_loss: 2.7111 - val_accuracy: 0.7108\n",
      "Epoch 330/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2586 - accuracy: 0.9274 - val_loss: 2.3920 - val_accuracy: 0.7353\n",
      "Epoch 331/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1957 - accuracy: 0.9365 - val_loss: 2.2413 - val_accuracy: 0.7598\n",
      "Epoch 332/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3504 - accuracy: 0.9072 - val_loss: 1.9227 - val_accuracy: 0.7745\n",
      "Epoch 333/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2095 - accuracy: 0.9253 - val_loss: 1.9319 - val_accuracy: 0.7451\n",
      "Epoch 334/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1908 - accuracy: 0.9392 - val_loss: 2.5318 - val_accuracy: 0.7353\n",
      "Epoch 335/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1676 - accuracy: 0.9477 - val_loss: 1.8797 - val_accuracy: 0.7892\n",
      "Epoch 336/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1279 - accuracy: 0.9594 - val_loss: 1.8691 - val_accuracy: 0.7794\n",
      "Epoch 337/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1456 - accuracy: 0.9573 - val_loss: 2.4606 - val_accuracy: 0.7451\n",
      "Epoch 338/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2516 - accuracy: 0.9285 - val_loss: 2.4065 - val_accuracy: 0.7353\n",
      "Epoch 339/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3700 - accuracy: 0.9050 - val_loss: 2.4301 - val_accuracy: 0.7500\n",
      "Epoch 340/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2808 - accuracy: 0.9221 - val_loss: 2.1710 - val_accuracy: 0.7353\n",
      "Epoch 341/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1716 - accuracy: 0.9456 - val_loss: 1.9117 - val_accuracy: 0.7745\n",
      "Epoch 342/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1417 - accuracy: 0.9552 - val_loss: 2.0512 - val_accuracy: 0.7745\n",
      "Epoch 343/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1441 - accuracy: 0.9520 - val_loss: 2.0301 - val_accuracy: 0.7500\n",
      "Epoch 344/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2465 - accuracy: 0.9296 - val_loss: 2.0693 - val_accuracy: 0.7255\n",
      "Epoch 345/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1447 - accuracy: 0.9488 - val_loss: 2.2155 - val_accuracy: 0.7696\n",
      "Epoch 346/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1905 - accuracy: 0.9424 - val_loss: 2.2477 - val_accuracy: 0.7451\n",
      "Epoch 347/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1743 - accuracy: 0.9456 - val_loss: 2.5065 - val_accuracy: 0.7647\n",
      "Epoch 348/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1499 - accuracy: 0.9594 - val_loss: 2.4173 - val_accuracy: 0.7745\n",
      "Epoch 349/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1530 - accuracy: 0.9488 - val_loss: 2.3109 - val_accuracy: 0.7794\n",
      "Epoch 350/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1102 - accuracy: 0.9637 - val_loss: 2.1586 - val_accuracy: 0.7843\n",
      "Epoch 351/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1113 - accuracy: 0.9648 - val_loss: 2.0104 - val_accuracy: 0.8039\n",
      "Epoch 352/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1708 - accuracy: 0.9637 - val_loss: 2.2539 - val_accuracy: 0.8039\n",
      "Epoch 353/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1319 - accuracy: 0.9573 - val_loss: 2.1132 - val_accuracy: 0.7892\n",
      "Epoch 354/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1380 - accuracy: 0.9626 - val_loss: 2.1531 - val_accuracy: 0.8039\n",
      "Epoch 355/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1191 - accuracy: 0.9626 - val_loss: 2.3830 - val_accuracy: 0.7647\n",
      "Epoch 356/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1065 - accuracy: 0.9637 - val_loss: 2.0756 - val_accuracy: 0.7794\n",
      "Epoch 357/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1334 - accuracy: 0.9605 - val_loss: 2.3757 - val_accuracy: 0.7745\n",
      "Epoch 358/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1245 - accuracy: 0.9552 - val_loss: 2.5984 - val_accuracy: 0.7402\n",
      "Epoch 359/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1736 - accuracy: 0.9434 - val_loss: 2.5139 - val_accuracy: 0.7696\n",
      "Epoch 360/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1488 - accuracy: 0.9477 - val_loss: 2.5347 - val_accuracy: 0.7549\n",
      "Epoch 361/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1678 - accuracy: 0.9520 - val_loss: 2.3036 - val_accuracy: 0.7696\n",
      "Epoch 362/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2376 - accuracy: 0.9328 - val_loss: 2.2912 - val_accuracy: 0.7745\n",
      "Epoch 363/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2300 - accuracy: 0.9306 - val_loss: 2.1947 - val_accuracy: 0.7696\n",
      "Epoch 364/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1571 - accuracy: 0.9552 - val_loss: 2.3438 - val_accuracy: 0.7549\n",
      "Epoch 365/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1684 - accuracy: 0.9477 - val_loss: 2.4175 - val_accuracy: 0.7549\n",
      "Epoch 366/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1931 - accuracy: 0.9338 - val_loss: 2.5365 - val_accuracy: 0.7598\n",
      "Epoch 367/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2086 - accuracy: 0.9328 - val_loss: 2.6623 - val_accuracy: 0.7353\n",
      "Epoch 368/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1982 - accuracy: 0.9360 - val_loss: 2.5892 - val_accuracy: 0.7598\n",
      "Epoch 369/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1369 - accuracy: 0.9530 - val_loss: 2.6224 - val_accuracy: 0.7402\n",
      "Epoch 370/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1138 - accuracy: 0.9616 - val_loss: 2.2834 - val_accuracy: 0.7696\n",
      "Epoch 371/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0934 - accuracy: 0.9680 - val_loss: 2.2682 - val_accuracy: 0.7500\n",
      "Epoch 372/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0967 - accuracy: 0.9680 - val_loss: 2.2570 - val_accuracy: 0.7745\n",
      "Epoch 373/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1015 - accuracy: 0.9658 - val_loss: 2.2377 - val_accuracy: 0.7892\n",
      "Epoch 374/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0926 - accuracy: 0.9691 - val_loss: 2.2560 - val_accuracy: 0.7794\n",
      "Epoch 375/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0961 - accuracy: 0.9656 - val_loss: 2.2839 - val_accuracy: 0.7745\n",
      "Epoch 376/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0820 - accuracy: 0.9712 - val_loss: 2.2843 - val_accuracy: 0.7794\n",
      "Epoch 377/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0997 - accuracy: 0.9669 - val_loss: 2.3123 - val_accuracy: 0.7794\n",
      "Epoch 378/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1095 - accuracy: 0.9626 - val_loss: 2.3275 - val_accuracy: 0.7696\n",
      "Epoch 379/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 2.3285 - val_accuracy: 0.7843\n",
      "Epoch 380/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0936 - accuracy: 0.9691 - val_loss: 2.3565 - val_accuracy: 0.7794\n",
      "Epoch 381/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0872 - accuracy: 0.9680 - val_loss: 2.3617 - val_accuracy: 0.7794\n",
      "Epoch 382/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0769 - accuracy: 0.9733 - val_loss: 2.3780 - val_accuracy: 0.7794\n",
      "Epoch 383/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0955 - accuracy: 0.9648 - val_loss: 2.3677 - val_accuracy: 0.7794\n",
      "Epoch 384/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0928 - accuracy: 0.9680 - val_loss: 2.4149 - val_accuracy: 0.7794\n",
      "Epoch 385/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 2.3892 - val_accuracy: 0.7745\n",
      "Epoch 386/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0956 - accuracy: 0.9635 - val_loss: 2.3909 - val_accuracy: 0.7794\n",
      "Epoch 387/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 2.3887 - val_accuracy: 0.7843\n",
      "Epoch 388/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0996 - accuracy: 0.9637 - val_loss: 2.4159 - val_accuracy: 0.7696\n",
      "Epoch 389/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 2.4195 - val_accuracy: 0.7843\n",
      "Epoch 390/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1017 - accuracy: 0.9658 - val_loss: 2.4274 - val_accuracy: 0.7794\n",
      "Epoch 391/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0873 - accuracy: 0.9701 - val_loss: 2.4442 - val_accuracy: 0.7794\n",
      "Epoch 392/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0925 - accuracy: 0.9658 - val_loss: 2.4545 - val_accuracy: 0.7794\n",
      "Epoch 393/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0945 - accuracy: 0.9648 - val_loss: 2.4539 - val_accuracy: 0.7745\n",
      "Epoch 394/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0787 - accuracy: 0.9701 - val_loss: 2.4701 - val_accuracy: 0.7794\n",
      "Epoch 395/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1045 - accuracy: 0.9626 - val_loss: 2.4724 - val_accuracy: 0.7843\n",
      "Epoch 396/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0805 - accuracy: 0.9701 - val_loss: 2.4828 - val_accuracy: 0.7843\n",
      "Epoch 397/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0917 - accuracy: 0.9688 - val_loss: 2.4933 - val_accuracy: 0.7794\n",
      "Epoch 398/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0939 - accuracy: 0.9669 - val_loss: 2.4962 - val_accuracy: 0.7794\n",
      "Epoch 399/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0907 - accuracy: 0.9680 - val_loss: 2.4969 - val_accuracy: 0.7843\n",
      "Epoch 400/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0708 - accuracy: 0.9755 - val_loss: 2.5106 - val_accuracy: 0.7843\n",
      "Epoch 401/500\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.0996 - accuracy: 0.9669 - val_loss: 2.5185 - val_accuracy: 0.7843\n",
      "Epoch 402/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0929 - accuracy: 0.9658 - val_loss: 2.5248 - val_accuracy: 0.7843\n",
      "Epoch 403/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1067 - accuracy: 0.9605 - val_loss: 2.5380 - val_accuracy: 0.7892\n",
      "Epoch 404/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 2.5368 - val_accuracy: 0.7843\n",
      "Epoch 405/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0870 - accuracy: 0.9701 - val_loss: 2.5393 - val_accuracy: 0.7843\n",
      "Epoch 406/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.96 - 1s 25ms/step - loss: 0.0975 - accuracy: 0.9658 - val_loss: 2.5498 - val_accuracy: 0.7843\n",
      "Epoch 407/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0910 - accuracy: 0.9680 - val_loss: 2.5598 - val_accuracy: 0.7794\n",
      "Epoch 408/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 2.5656 - val_accuracy: 0.7794\n",
      "Epoch 409/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0877 - accuracy: 0.9701 - val_loss: 2.5705 - val_accuracy: 0.7794\n",
      "Epoch 410/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0776 - accuracy: 0.9723 - val_loss: 2.5735 - val_accuracy: 0.7892\n",
      "Epoch 411/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0908 - accuracy: 0.9669 - val_loss: 2.5901 - val_accuracy: 0.7892\n",
      "Epoch 412/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1036 - accuracy: 0.9616 - val_loss: 2.5757 - val_accuracy: 0.7843\n",
      "Epoch 413/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0866 - accuracy: 0.9701 - val_loss: 2.5778 - val_accuracy: 0.7843\n",
      "Epoch 414/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0880 - accuracy: 0.9669 - val_loss: 2.5913 - val_accuracy: 0.7843\n",
      "Epoch 415/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0888 - accuracy: 0.9691 - val_loss: 2.6039 - val_accuracy: 0.7794\n",
      "Epoch 416/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0975 - accuracy: 0.9637 - val_loss: 2.6041 - val_accuracy: 0.7843\n",
      "Epoch 417/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 2.6095 - val_accuracy: 0.7843\n",
      "Epoch 418/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0957 - accuracy: 0.9669 - val_loss: 2.6120 - val_accuracy: 0.7843\n",
      "Epoch 419/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 2.6134 - val_accuracy: 0.7843\n",
      "Epoch 420/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0912 - accuracy: 0.9658 - val_loss: 2.6218 - val_accuracy: 0.7843\n",
      "Epoch 421/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1466 - accuracy: 0.9605 - val_loss: 3.1942 - val_accuracy: 0.7157\n",
      "Epoch 422/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 1.4778 - accuracy: 0.7823 - val_loss: 4.0202 - val_accuracy: 0.5833\n",
      "Epoch 423/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 1.0572 - accuracy: 0.8100 - val_loss: 1.7832 - val_accuracy: 0.7402\n",
      "Epoch 424/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6218 - accuracy: 0.8559 - val_loss: 2.5028 - val_accuracy: 0.6863\n",
      "Epoch 425/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3091 - accuracy: 0.9050 - val_loss: 1.9609 - val_accuracy: 0.7304\n",
      "Epoch 426/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2589 - accuracy: 0.9200 - val_loss: 2.0116 - val_accuracy: 0.7794\n",
      "Epoch 427/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2307 - accuracy: 0.9285 - val_loss: 1.7777 - val_accuracy: 0.7696\n",
      "Epoch 428/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2018 - accuracy: 0.9402 - val_loss: 1.9443 - val_accuracy: 0.7696\n",
      "Epoch 429/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1391 - accuracy: 0.9584 - val_loss: 2.1163 - val_accuracy: 0.8039\n",
      "Epoch 430/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1337 - accuracy: 0.9573 - val_loss: 2.0500 - val_accuracy: 0.7843\n",
      "Epoch 431/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1458 - accuracy: 0.9562 - val_loss: 1.6765 - val_accuracy: 0.7941\n",
      "Epoch 432/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1305 - accuracy: 0.9573 - val_loss: 1.9943 - val_accuracy: 0.7549\n",
      "Epoch 433/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1752 - accuracy: 0.9424 - val_loss: 1.8345 - val_accuracy: 0.7892\n",
      "Epoch 434/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1262 - accuracy: 0.9573 - val_loss: 1.8104 - val_accuracy: 0.8039\n",
      "Epoch 435/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1113 - accuracy: 0.9648 - val_loss: 1.8475 - val_accuracy: 0.7990\n",
      "Epoch 436/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1170 - accuracy: 0.9616 - val_loss: 1.8291 - val_accuracy: 0.7892\n",
      "Epoch 437/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1212 - accuracy: 0.9626 - val_loss: 2.0488 - val_accuracy: 0.7990\n",
      "Epoch 438/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1140 - accuracy: 0.9648 - val_loss: 2.0388 - val_accuracy: 0.8039\n",
      "Epoch 439/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1079 - accuracy: 0.9658 - val_loss: 1.8356 - val_accuracy: 0.8088\n",
      "Epoch 440/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0925 - accuracy: 0.9701 - val_loss: 1.9005 - val_accuracy: 0.8088\n",
      "Epoch 441/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0896 - accuracy: 0.9698 - val_loss: 1.8799 - val_accuracy: 0.8137\n",
      "Epoch 442/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0986 - accuracy: 0.9658 - val_loss: 1.9038 - val_accuracy: 0.8137\n",
      "Epoch 443/500\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0954 - accuracy: 0.9680 - val_loss: 1.9039 - val_accuracy: 0.8137\n",
      "Epoch 444/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0830 - accuracy: 0.9733 - val_loss: 1.8979 - val_accuracy: 0.8088\n",
      "Epoch 445/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0870 - accuracy: 0.9691 - val_loss: 1.9224 - val_accuracy: 0.8088\n",
      "Epoch 446/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1111 - accuracy: 0.9605 - val_loss: 1.9333 - val_accuracy: 0.8039\n",
      "Epoch 447/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0834 - accuracy: 0.9723 - val_loss: 1.9243 - val_accuracy: 0.8186\n",
      "Epoch 448/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0999 - accuracy: 0.9648 - val_loss: 1.9504 - val_accuracy: 0.8137\n",
      "Epoch 449/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1478 - accuracy: 0.9509 - val_loss: 2.9184 - val_accuracy: 0.6471\n",
      "Epoch 450/500\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.1720 - accuracy: 0.9445 - val_loss: 2.2714 - val_accuracy: 0.7745\n",
      "Epoch 451/500\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1917 - accuracy: 0.9349 - val_loss: 2.2299 - val_accuracy: 0.7647\n",
      "Epoch 452/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2940 - accuracy: 0.9042 - val_loss: 2.4918 - val_accuracy: 0.7549\n",
      "Epoch 453/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3832 - accuracy: 0.9104 - val_loss: 2.0712 - val_accuracy: 0.7598\n",
      "Epoch 454/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2696 - accuracy: 0.9360 - val_loss: 2.3735 - val_accuracy: 0.7598\n",
      "Epoch 455/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1381 - accuracy: 0.9605 - val_loss: 2.2053 - val_accuracy: 0.7696\n",
      "Epoch 456/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0971 - accuracy: 0.9723 - val_loss: 2.1493 - val_accuracy: 0.7794\n",
      "Epoch 457/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1025 - accuracy: 0.9648 - val_loss: 2.0468 - val_accuracy: 0.7941\n",
      "Epoch 458/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0986 - accuracy: 0.9701 - val_loss: 1.9901 - val_accuracy: 0.7941\n",
      "Epoch 459/500\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.0969 - accuracy: 0.9669 - val_loss: 2.0996 - val_accuracy: 0.7892\n",
      "Epoch 460/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1006 - accuracy: 0.9658 - val_loss: 2.0171 - val_accuracy: 0.7941\n",
      "Epoch 461/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0973 - accuracy: 0.9691 - val_loss: 2.0658 - val_accuracy: 0.7941\n",
      "Epoch 462/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 2.0911 - val_accuracy: 0.7941\n",
      "Epoch 463/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0885 - accuracy: 0.9698 - val_loss: 2.0794 - val_accuracy: 0.7941\n",
      "Epoch 464/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1032 - accuracy: 0.9637 - val_loss: 2.0729 - val_accuracy: 0.7941\n",
      "Epoch 465/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0945 - accuracy: 0.9658 - val_loss: 2.0976 - val_accuracy: 0.7941\n",
      "Epoch 466/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 2.0948 - val_accuracy: 0.7941\n",
      "Epoch 467/500\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0796 - accuracy: 0.9701 - val_loss: 2.1511 - val_accuracy: 0.7990\n",
      "Epoch 468/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0899 - accuracy: 0.9669 - val_loss: 2.1157 - val_accuracy: 0.7990\n",
      "Epoch 469/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1178 - accuracy: 0.9562 - val_loss: 2.1233 - val_accuracy: 0.7990\n",
      "Epoch 470/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 2.1228 - val_accuracy: 0.7990\n",
      "Epoch 471/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0956 - accuracy: 0.9648 - val_loss: 2.1269 - val_accuracy: 0.7941\n",
      "Epoch 472/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0838 - accuracy: 0.9712 - val_loss: 2.1406 - val_accuracy: 0.7941\n",
      "Epoch 473/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0918 - accuracy: 0.9680 - val_loss: 2.1557 - val_accuracy: 0.7941\n",
      "Epoch 474/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0950 - accuracy: 0.9677 - val_loss: 2.1844 - val_accuracy: 0.7892\n",
      "Epoch 475/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 2.1472 - val_accuracy: 0.7990\n",
      "Epoch 476/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0932 - accuracy: 0.9669 - val_loss: 2.1618 - val_accuracy: 0.7941\n",
      "Epoch 477/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0915 - accuracy: 0.9669 - val_loss: 2.1890 - val_accuracy: 0.7941\n",
      "Epoch 478/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0746 - accuracy: 0.9755 - val_loss: 2.1739 - val_accuracy: 0.7990\n",
      "Epoch 479/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1115 - accuracy: 0.9594 - val_loss: 2.1986 - val_accuracy: 0.7892\n",
      "Epoch 480/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0952 - accuracy: 0.9658 - val_loss: 2.1862 - val_accuracy: 0.7990\n",
      "Epoch 481/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0850 - accuracy: 0.9701 - val_loss: 2.2364 - val_accuracy: 0.7941\n",
      "Epoch 482/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0893 - accuracy: 0.9691 - val_loss: 2.2125 - val_accuracy: 0.7892\n",
      "Epoch 483/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0913 - accuracy: 0.9669 - val_loss: 2.2062 - val_accuracy: 0.7892\n",
      "Epoch 484/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0875 - accuracy: 0.9680 - val_loss: 2.2260 - val_accuracy: 0.7892\n",
      "Epoch 485/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0917 - accuracy: 0.9656 - val_loss: 2.2279 - val_accuracy: 0.7941\n",
      "Epoch 486/500\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 2.2224 - val_accuracy: 0.7941\n",
      "Epoch 487/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0926 - accuracy: 0.9669 - val_loss: 2.2488 - val_accuracy: 0.7892\n",
      "Epoch 488/500\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0868 - accuracy: 0.9691 - val_loss: 2.2341 - val_accuracy: 0.7941\n",
      "Epoch 489/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0881 - accuracy: 0.9701 - val_loss: 2.2348 - val_accuracy: 0.7941\n",
      "Epoch 490/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1012 - accuracy: 0.9626 - val_loss: 2.2616 - val_accuracy: 0.7843\n",
      "Epoch 491/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0763 - accuracy: 0.9723 - val_loss: 2.2503 - val_accuracy: 0.7892\n",
      "Epoch 492/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 2.2503 - val_accuracy: 0.7892\n",
      "Epoch 493/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0892 - accuracy: 0.9691 - val_loss: 2.2492 - val_accuracy: 0.7892\n",
      "Epoch 494/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0818 - accuracy: 0.9723 - val_loss: 2.2804 - val_accuracy: 0.7843\n",
      "Epoch 495/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0937 - accuracy: 0.9648 - val_loss: 2.2577 - val_accuracy: 0.7941\n",
      "Epoch 496/500\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0906 - accuracy: 0.9667 - val_loss: 2.2661 - val_accuracy: 0.7941\n",
      "Epoch 497/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0890 - accuracy: 0.9658 - val_loss: 2.2718 - val_accuracy: 0.7941\n",
      "Epoch 498/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0845 - accuracy: 0.9723 - val_loss: 2.2761 - val_accuracy: 0.7941\n",
      "Epoch 499/500\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0808 - accuracy: 0.9733 - val_loss: 2.2879 - val_accuracy: 0.7892\n",
      "Epoch 500/500\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1083 - accuracy: 0.9594 - val_loss: 2.2701 - val_accuracy: 0.7941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29836df4cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model\n",
    "model.fit(x_train, y_train, epochs=500, steps_per_epoch=30, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thirty-edwards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved into model_SIBI.h5\n"
     ]
    }
   ],
   "source": [
    "#Saving the model into H5 system file\n",
    "save_model = \"model_SIBI.h5\"\n",
    "model.save(save_model)\n",
    "print(\"Model Saved into\", save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model for TF-Serving Type\n",
    "import os\n",
    "\n",
    "MODEL_DIR = \"server_model_SIBI\"\n",
    "\n",
    "version = 1\n",
    "\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "\n",
    "if os.path.isdir(export_path):\n",
    "    print('\\nAlready saved a model, cleaning up\\n')\n",
    "    !rm -r {export_path}\n",
    "\n",
    "model.save(export_path, save_format=\"tf\")\n",
    "\n",
    "print('\\nexport_path = {}'.format(export_path))\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alien-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 42, 1)\n",
      "[[[1103.327]\n",
      "  [1540.716]\n",
      "  [ 855.426]\n",
      "  [1411.774]\n",
      "  [ 683.308]\n",
      "  [1153.357]\n",
      "  [ 558.997]\n",
      "  [ 959.797]\n",
      "  [ 387.358]\n",
      "  [ 854.781]\n",
      "  [ 934.849]\n",
      "  [ 893.382]\n",
      "  [ 925.604]\n",
      "  [ 639.385]\n",
      "  [ 920.373]\n",
      "  [ 475.725]\n",
      "  [ 924.981]\n",
      "  [ 324.413]\n",
      "  [1102.588]\n",
      "  [ 946.422]\n",
      "  [1137.946]\n",
      "  [ 746.217]\n",
      "  [1086.862]\n",
      "  [1009.154]\n",
      "  [1076.11 ]\n",
      "  [1152.22 ]\n",
      "  [1254.827]\n",
      "  [1021.595]\n",
      "  [1289.853]\n",
      "  [ 855.331]\n",
      "  [1201.73 ]\n",
      "  [1101.462]\n",
      "  [1185.479]\n",
      "  [1216.182]\n",
      "  [1399.912]\n",
      "  [1116.804]\n",
      "  [1421.615]\n",
      "  [ 964.66 ]\n",
      "  [1333.269]\n",
      "  [1121.019]\n",
      "  [1310.715]\n",
      "  [1211.711]]]\n"
     ]
    }
   ],
   "source": [
    "#Testing the Model\n",
    "input_test = [[[1103.32715511], [1540.71593285],\n",
    "               [ 855.42565584],[1411.77392006],[ 683.30776691],[1153.35738659],[ 558.99703503],[ 959.79690552],[ 387.35830784],[ 854.78103161],\n",
    "               [ 934.84920263],[ 893.38219166],[ 925.60398579],[ 639.38450813],[ 920.37254572],[ 475.72478652],[ 924.98147488],[ 324.41276312],\n",
    "               [1102.58769989],[ 946.42174244],[1137.94636726],[ 746.21725082],[1086.86184883],[1009.15443897],[1076.11000538],[1152.21977234],\n",
    "               [1254.82654572],[1021.59452438],[1289.85261917],[ 855.33124208],[1201.73048973],[1101.46188736],[1185.47868729],[1216.18199348],\n",
    "               [1399.91247654],[1116.8037653 ],[1421.61536217],[ 964.65975046],[1333.26935768],[1121.01900578],[1310.71531773],[1211.71069145]]]\n",
    "input_test = np.array(input_test)\n",
    "input = np.reshape(input_test, (input_test.shape[0], input_test.shape[1], 1))\n",
    "print(input_test.shape)\n",
    "print(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ranking-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "WARNING:tensorflow:From <ipython-input-18-ce52a49e73f2>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[11]\n"
     ]
    }
   ],
   "source": [
    "#Print the Prediction\n",
    "print(model.predict(input_test))\n",
    "print(model.predict_classes(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "historical-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25\n",
    "}\n",
    "\n",
    "predictions = model.predict_classes(input_test)\n",
    "for alphabets, values in classes.items():\n",
    "    if values == predictions[0] :\n",
    "        print(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-breakfast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
